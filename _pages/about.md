---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

# üëã _About Me_ <!-- ![visitors](https://visitor-badge.laobi.icu/badge?page_id=zhangzhang2024.github.io) -->
- üéì I am currently a Ph.D student at School of Mechanical Engineering, Beijing Institute of Technology, advised by **<a href="https://scholar.google.com/citations?user=aUnzdwIAAAAJ&hl=zh-CN&oi=ao" style="text-decoration: none;">Prof. Chao Sun</a>**. 
- ü§ó I have been fortunate to collaborate with **<a href="https://x-humanoid.com/" style="text-decoration: none;">Beijing Innovation Center of Humanoid Robotics</a>**.
- ‚ú® My current research interests focus on: **V2X**, **Embodied Agents**, **World Models**.
- üì´ If you are interested in academic collaboration, feel free to reach me via **<a href="mailto:zhangzhang00@bit.edu.cn" style="text-decoration: none;">zhangzhang00@bit.edu.cn</a>** ‚Äî I'd love to connect!
  

<!-- # üìñ Educations
- *2022 - Present*, PhD student, School of Machanical Engineering, Beijing Institute of Technology. **<a href="zhangzhang00@bit.edu.cn" style="text-decoration: none;">zhangzhang00@bit.edu.cn</a>**
- *2018 - 2022*, Undergrad student, School of Machanical Engineering, Beijing Institute of Technology. -->

# üî• _News_
- _2025.04: &nbsp; Occupancy World Model for Robots_
- _2025.04: &nbsp; RoboOcc: Enhancing the Geometric and Semantic Scene Understanding for Robots_
- _2025.04: &nbsp; RoadFormer: Road Surface Classification Using Local-Global Feature Fusion_
- _2025.03: &nbsp; Q-MambaIR: Accurate Quantized Mamba for Efficient Image Restoration_
- _2025.03: &nbsp; HumanoidPano: Hybrid Spherical Panoramic-LiDAR Cross-Modal Perception for Humanoid Robots_
- _2025.01: &nbsp; PillarMamba: Learning Dense Context Information for Roadside Point Cloud 3D Object Detection via State Space Model_
- _2024.12: &nbsp; HeightFormer: Learning Height Prediction in Voxel Features for Roadside Vision Centric 3D Object Detection via Transformer_
- _2024.11: &nbsp; PillarID: Rethinking Backbone Network Designs for Pillar-based 3D Object Detection in Infrastructure Point Cloud_
- _2024.10: &nbsp; Height3D: A Roadside Visual Framework Based on Height Prediction in Real 3D Space_

# ‚≠ê _Selected Papers_
<div class='paper-box'><div class='paper-box-image' style="display: inline-block; vertical-align: top; margin: 0; padding: 0;">
  <div><img src='images/robooccworld.png' alt="sym" width="400" height="300"></div></div>
<div class='paper-box-text' markdown="1" style="font-size: 14px;">
**[Occupancy World Model for Robots]**
  
_<span style="color: #000000;">**Zhang Zhang\***</span>, Qiang Zhang\*, Wei Cui\*, Shuai Shi, Yijie Guo, Gang Han, Wen Zhao, Hengle Ren, Renjing Xu, Jian Tang_

_Under review_

- _We restructure the OccWorld-ScanNet benchmark to evaluate the forecasting of scene evolutions._
- _We propose a occupancy world model for robots' decision and exploration._
</div>
</div>

<div class='paper-box'><div class='paper-box-image' style="display: inline-block; vertical-align: top; margin: 0; padding: 0;">
  <div><img src='images/roboocc.png' alt="sym" width="400" height="300"></div></div>
<div class='paper-box-text' markdown="1" style="font-size: 14px;">
**<a href="https://arxiv.org/pdf/2504.14604.pdf" style="text-decoration: none;">RoboOcc: Enhancing the Geometric and Semantic Scene Understanding for Robots</a>**
  
_<span style="color: #000000;">**Zhang Zhang\***</span>, Qiang Zhang\*, Wei Cui\*, Shuai Shi, Yijie Guo, Gang Han, Wen Zhao, Hengle Ren, Renjing Xu, Jian Tang_

_Under review_

- _We present a method to enhance geometric and semantic scene understanding in 3D occupancy prediction for robots._
</div>
</div>

<div class='paper-box'><div class='paper-box-image' style="display: inline-block; vertical-align: top; margin: 0; padding: 0;">
  <div><img src='images/h-pano.png' alt="sym" width="400" height="300"></div></div>
<div class='paper-box-text' markdown="1" style="font-size: 14px;">
**<a href="https://arxiv.org/pdf/2503.09010.pdf" style="text-decoration: none;">HumanoidPano: Hybrid Spherical Panoramic-LiDAR Cross-Modal Perception for Humanoid Robots</a>**
  
_Qiang Zhang\*, <span style="color: #000000;">**Zhang Zhang\***</span>, Wei Cui\*, Jingkai Sun, Jiahang Cao, Yijie Guo, Gang Han, Wen Zhao, Jiaxu Wang, Chenghao Sun, Lingfeng Zhang, Hao Cheng, Yujie Chen, Lin Wang, Jian Tang, Renjing Xu_

_Under review_

- _We propose a novel hybrid cross-modal perception framework that synergistically integrates panoramic vision and LiDAR sensing for humanoid robots._
</div>
</div>

<div class='paper-box'><div class='paper-box-image' style="display: inline-block; vertical-align: top; margin: 0; padding: 0;">
  <div><img src='images/heightformer.png' alt="sym" width="400" height="300"></div></div>
<div class='paper-box-text' markdown="1" style="font-size: 14px;">
**<a href="https://arxiv.org/pdf/2503.10777.pdf" style="text-decoration: none;">HeightFormer: Learning Height Prediction in Voxel Features for Roadside Vision Centric 3D Object Detection via Transformer</a>**
  
_<span style="color: #000000;">**Zhang Zhang**</span>, Chao Sun, Chao Yue, Da Wen, Yujie Chen, Tianze Wang, Jianghao Leng_

_Under review_

- _We propose an efficient framework learning height prediction in voxel features via transformer for roadside visual perception._
</div>
</div>

# üé® _All Papers_
<div class='paper-box'><div class='paper-box-image' style="display: inline-block; vertical-align: top; margin: 0; padding: 0;">
  <div><img src='images/robooccworld.png' alt="sym" width="400" height="300"></div></div>
<div class='paper-box-text' markdown="1" style="font-size: 14px;">
**[Occupancy World Model for Robots]**
  
_<span style="color: #000000;">**Zhang Zhang\***</span>, Qiang Zhang\*, Wei Cui\*, Shuai Shi, Yijie Guo, Gang Han, Wen Zhao, Hengle Ren, Renjing Xu, Jian Tang_

_Under review_

- _We restructure the OccWorld-ScanNet benchmark to evaluate the forecasting of scene evolutions._
- _We propose a occupancy world model for robots' decision and exploration._
</div>
</div>

<div class='paper-box'><div class='paper-box-image' style="display: inline-block; vertical-align: top; margin: 0; padding: 0;">
  <div><img src='images/roboocc.png' alt="sym" width="400" height="300"></div></div>
<div class='paper-box-text' markdown="1" style="font-size: 14px;">
**<a href="https://arxiv.org/pdf/2504.14604.pdf" style="text-decoration: none;">RoboOcc: Enhancing the Geometric and Semantic Scene Understanding for Robots</a>**
  
_<span style="color: #000000;">**Zhang Zhang\***</span>, Qiang Zhang\*, Wei Cui\*, Shuai Shi, Yijie Guo, Gang Han, Wen Zhao, Hengle Ren, Renjing Xu, Jian Tang_

_Under review_

- _We present a method to enhance geometric and semantic scene understanding in 3D occupancy prediction for robots._
</div>
</div>

<div class='paper-box'><div class='paper-box-image' style="display: inline-block; vertical-align: top; margin: 0; padding: 0;">
  <div><img src='images/roadformer.png' alt="sym" width="400" height="300"></div></div>
<div class='paper-box-text' markdown="1" style="font-size: 14px;">
**[RoadFormer: Road Surface Classification Using Local-Global Feature Fusion]**
  
_Tianze Wang\*, <span style="color: #000000;">**Zhang Zhang\***</span>, Chao Sun, To do_

_To do_

- _We propose a feature stacking method that comprehensively considers both local and global information for road surface classification._
</div>
</div>

<div class='paper-box'><div class='paper-box-image' style="display: inline-block; vertical-align: top; margin: 0; padding: 0;">
  <div><img src='images/pillarmamba.png' alt="sym" width="400" height="300"></div></div>
<div class='paper-box-text' markdown="1" style="font-size: 14px;">
**[PillarMamba: Learning Dense Context Information for Roadside Point Cloud 3D Object Detection via State Space Model]**
  
_<span style="color: #000000;">**Zhang Zhang**</span>, Chao Sun, To do_

_To do_
</div>
</div>

<div class='paper-box'><div class='paper-box-image' style="display: inline-block; vertical-align: top; margin: 0; padding: 0;">
  <div><img src='images/h-pano.png' alt="sym" width="400" height="300"></div></div>
<div class='paper-box-text' markdown="1" style="font-size: 14px;">
**<a href="https://arxiv.org/pdf/2503.09010.pdf" style="text-decoration: none;">HumanoidPano: Hybrid Spherical Panoramic-LiDAR Cross-Modal Perception for Humanoid Robots</a>**
  
_Qiang Zhang\*, <span style="color: #000000;">**Zhang Zhang\***</span>, Wei Cui\*, Jingkai Sun, Jiahang Cao, Yijie Guo, Gang Han, Wen Zhao, Jiaxu Wang, Chenghao Sun, Lingfeng Zhang, Hao Cheng, Yujie Chen, Lin Wang, Jian Tang, Renjing Xu_

_Under review_

- _We propose a novel hybrid cross-modal perception framework that synergistically integrates panoramic vision and LiDAR sensing for humanoid robots._
</div>
</div>

<div class='paper-box'><div class='paper-box-image' style="display: inline-block; vertical-align: top; margin: 0; padding: 0;">
  <div><img src='images/qmambair.jpg' alt="sym" width="400" height="300"></div></div>
<div class='paper-box-text' markdown="1" style="font-size: 14px;">
**<a href="https://arxiv.org/pdf/2503.21970.pdf" style="text-decoration: none;">Q-MambaIR: Accurate Quantized Mamba for Efficient Image Restoration</a>**
  
_Yujie Chen, Haotong Qin, <span style="color: #000000;">**Zhang Zhang**</span>, Michelo Magno, Luca Benini, Yawei Li_

_Under review_

- _We propose an accurate, efficient, and flexible quantized mamaba for image restoration task._
</div>
</div>

<div class='paper-box'><div class='paper-box-image' style="display: inline-block; vertical-align: top; margin: 0; padding: 0;">
  <div><img src='images/heightformer.png' alt="sym" width="400" height="300"></div></div>
<div class='paper-box-text' markdown="1" style="font-size: 14px;">
**<a href="https://arxiv.org/pdf/2503.10777.pdf" style="text-decoration: none;">HeightFormer: Learning Height Prediction in Voxel Features for Roadside Vision Centric 3D Object Detection via Transformer</a>**
  
_<span style="color: #000000;">**Zhang Zhang**</span>, Chao Sun, Chao Yue, Da Wen, Yujie Chen, Tianze Wang, Jianghao Leng_

_Under review_

- _We propose an efficient framework learning height prediction in voxel features via transformer for roadside visual perception._
</div>
</div>

<div class='paper-box'><div class='paper-box-image' style="display: inline-block; vertical-align: top; margin: 0; padding: 0;">
  <div><img src='images/pillarid.png' alt="sym" width="400" height="300"></div></div>
<div class='paper-box-text' markdown="1" style="font-size: 14px;">
**[PillarID: Rethinking Backbone Network Designs for Pillar-based 3D Object Detection in Infrastructure Point Cloud]**
  
_<span style="color: #000000;">**Zhang Zhang**</span>, Chao Sun, Bo Wang, Da Wen_

_Under review_

- _We propose a dense backbone-based network for utilizing the rich contextual information of the roadside point cloud effectively._
</div>
</div>

<div class='paper-box'><div class='paper-box-image' style="display: inline-block; vertical-align: top; margin: 0; padding: 0;">
  <div><img src='images/height3d.png' alt="sym" width="400" height="300"></div></div>
<div class='paper-box-text' markdown="1" style="font-size: 14px;">
**[Height3D: A Roadside Visual Framework Based on Height Prediction in Real 3D Space]**
  
_<span style="color: #000000;">**Zhang Zhang**</span>, Chao Sun, Bo Wang, Bin Guo, Da Wen, Tianyi Zhu, Qili Ning_

_**<a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=6979" style="text-decoration: none;">IEEE Transactions on Intelligent Transportation Systems (TITS), 2025.</a>**_ 

- _We propose a novel roadside visual perception framework based on the heightnet in real 3D space instead of image 2D space._
</div>
</div>

<!--
[**Project**](https://scholar.google.com/citations?view_op=view_citation&hl=zh-CN&user=DhtAFkwAAAAJ&citation_for_view=DhtAFkwAAAAJ:ALROH1vI_8AC) <strong><span class='show_paper_citations' data='DhtAFkwAAAAJ:ALROH1vI_8AC'></span></strong>
- Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
</div>
</div>

- [Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet](https://github.com), A, B, C, **CVPR 2020**

# üéñ Honors and Awards
- *2021.10* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.09* Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 

# üí¨ Invited Talks
- *2021.06*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet. 
- *2021.03*, Lorem ipsum dolor sit amet, consectetur adipiscing elit. Vivamus ornare aliquet ipsum, ac tempus justo dapibus sit amet.  \| [\[video\]](https://github.com/)

# üíª Internships
- *2019.05 - 2020.02*, [Lorem](https://github.com/), China.
-->
